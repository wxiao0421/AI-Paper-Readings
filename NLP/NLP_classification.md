# NLP - Text Classification
|Paper|Conference|Remarks
|--|--|--|
|[Convolutional Neural Networks for Sentence Classification](https://www.aclweb.org/anthology/D14-1181)|EMNLP 2014|Show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.|
|[A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1510.03820)|Arxiv 2015|Conduct a sensitivity analysis of one-layer CNNs to explore the effect of architecture components on model performance, and to distinguish between important and comparatively inconsequential design decisions for sentence classification.|
|[Hierarchical Attention Networks for Document Classification](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf)|NAACL 2016|1. Propose a hierarchical attention network for document classification. 2. It has a hierarchical structure that mirrors the hierarchical structure of documents. 3. It has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. 4. Unclear about the interpretation of learned attention word and sentence.|
|[Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/pdf/1801.06146)|ACL 2018| 1. Propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. 2. Significantly outperforms the state-of-the-art on six text classification tasks|


[Back to index](../README.md)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE3OTgxOTg3MDksMjM3Nzg4Mjc5XX0=
-->