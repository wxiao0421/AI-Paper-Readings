# NLP - Machine Reading
|Paper|Conference|Remarks
|--|--|--|
|[Long Short-Term Memory-Networks for Machine Reading](https://aclweb.org/anthology/D16-1053)|EMNLP 2016|1. Propose a machine reading simulator which processes text incrementally from left to right and performs shallow reasoning with memory and attention. 2. Employ memory network in LSTM for adaptive memory usage during recurrence with neural attention, offering a way to weakly induce relations among tokens.|

[Back to index](../README.md)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTI2MzAwMDY1OF19
-->