# NLP - Text Summarization
|Paper|Conference|Remarks
|--|--|--|
|[Get To The Point: Summarization with Pointer-Generator Networks](https://aclanthology.info/papers/P17-1099/p17-1099)|ACL 2017|A novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. 1. A hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. 2. Uses coverage to keep track of what has been summarized, which discourages repetition.|
|[SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents](https://arxiv.org/pdf/1611.04230)|AAAI 2017| A Recurrent Neural Network (RNN) based sequence model for extractive summarization of documents with advantages of being very interpretable and being trainable on human generated reference summaries alone, eliminating the need for sentence-level extractive labels.|
|[Text Summarization Techniques: A Brief Survey](https://arxiv.org/pdf/1707.02268)|Arxiv 2017|Reviews the different processes for summarization and describe the effectiveness and shortcomings of the different methods.|

[Back to index](../README.md)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1NTAxOTQyOTNdfQ==
-->